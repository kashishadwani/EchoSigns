{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf73bde9-5521-464a-adf8-d3fcd00e9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import load_img  # Correct import for Keras image loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c49069e-34c4-415f-a4d7-fd276a313b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\minor_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16dbbdd-bf0c-4ad5-b7f4-0e0e118e890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    image = cv2.resize(image, (128, 128))  # Resize to match input shape\n",
    "    image = image / 255.0  # Normalize pixel values (0-1)\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension for CNN\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eff4d62-c448-41e4-a3c2-9d5dc3c16586",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93fae82-a12d-41a2-97d0-6614315be0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = r\"C:\\Users\\User\\minor_project\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b464af29-a7bc-46b6-8573-2bdaef05b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "for country in os.listdir(DATASET_PATH):\n",
    "    country_path = os.path.join(DATASET_PATH, country)\n",
    "    if os.path.isdir(country_path):  # Check if it's a folder\n",
    "        for letter in os.listdir(country_path):\n",
    "            label_key = f\"{country}/{letter}\"\n",
    "            label_value = f\"{country}_{letter}\"\n",
    "            labels_dict[label_key] = label_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cab34da-291f-495f-b293-2794ea43d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47912 images belonging to 5 classes.\n",
      "Found 11977 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_data = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "val_data = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ba6e15-71ff-41f0-87a6-46551f0fe918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['America', 'Filipino', 'India', 'Indonesia', 'Malaysia'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22278d49-5cfa-4fc5-9a27-0e2136f921ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['America/a', 'America/b', 'America/c', 'America/d', 'America/e', 'America/f', 'America/g', 'America/h', 'America/i', 'America/j', 'America/k', 'America/l', 'America/m', 'America/n', 'America/o', 'America/p', 'America/q', 'America/r', 'America/s', 'America/t', 'America/u', 'America/v', 'America/w', 'America/x', 'America/y', 'America/z', 'Filipino/A', 'Filipino/B', 'Filipino/C', 'Filipino/D', 'Filipino/E', 'Filipino/F', 'Filipino/G', 'Filipino/H', 'Filipino/I', 'Filipino/J', 'Filipino/K', 'Filipino/L', 'Filipino/M', 'Filipino/N', 'Filipino/O', 'Filipino/P', 'Filipino/Q', 'Filipino/R', 'Filipino/S', 'Filipino/T', 'Filipino/U', 'Filipino/V', 'Filipino/W', 'Filipino/X', 'Filipino/Y', 'Filipino/Z', 'India/A', 'India/B', 'India/C', 'India/D', 'India/E', 'India/F', 'India/G', 'India/H', 'India/I', 'India/J', 'India/K', 'India/L', 'India/M', 'India/N', 'India/O', 'India/P', 'India/Q', 'India/R', 'India/S', 'India/T', 'India/U', 'India/V', 'India/W', 'India/X', 'India/Y', 'India/Z', 'Indonesia/A', 'Indonesia/B', 'Indonesia/C', 'Indonesia/D', 'Indonesia/E', 'Indonesia/F', 'Indonesia/G', 'Indonesia/H', 'Indonesia/I', 'Indonesia/J', 'Indonesia/K', 'Indonesia/L', 'Indonesia/M', 'Indonesia/N', 'Indonesia/O', 'Indonesia/P', 'Indonesia/Q', 'Indonesia/R', 'Indonesia/S', 'Indonesia/T', 'Indonesia/U', 'Indonesia/V', 'Indonesia/W', 'Indonesia/X', 'Indonesia/Y', 'Indonesia/Z', 'Malaysia/A', 'Malaysia/B', 'Malaysia/C', 'Malaysia/D', 'Malaysia/E', 'Malaysia/F', 'Malaysia/G', 'Malaysia/H', 'Malaysia/I', 'Malaysia/J', 'Malaysia/K', 'Malaysia/L', 'Malaysia/M', 'Malaysia/N', 'Malaysia/O', 'Malaysia/P', 'Malaysia/Q', 'Malaysia/R', 'Malaysia/S', 'Malaysia/T', 'Malaysia/U', 'Malaysia/V', 'Malaysia/W', 'Malaysia/X', 'Malaysia/Y', 'Malaysia/Z'])\n"
     ]
    }
   ],
   "source": [
    "print(labels_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d34371-eacf-42dd-b352-833d5fadda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update the class indices to match 'America_A', 'America_B', etc.\n",
    "# train_data.class_indices = {labels_dict[key]: value for key, value in train_data.class_indices.items()}\n",
    "# train_data.class_indices = {labels_dict.get(key, key): value for key, value in train_data.class_indices.items()}\n",
    "train_data.class_indices= list(labels_dict.keys())\n",
    "val_data.class_indices = list(labels_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fd78d9-b4d0-4757-9c04-9119790ab8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['America/a', 'America/b', 'America/c', 'America/d', 'America/e', 'America/f', 'America/g', 'America/h', 'America/i', 'America/j', 'America/k', 'America/l', 'America/m', 'America/n', 'America/o', 'America/p', 'America/q', 'America/r', 'America/s', 'America/t', 'America/u', 'America/v', 'America/w', 'America/x', 'America/y', 'America/z', 'Filipino/A', 'Filipino/B', 'Filipino/C', 'Filipino/D', 'Filipino/E', 'Filipino/F', 'Filipino/G', 'Filipino/H', 'Filipino/I', 'Filipino/J', 'Filipino/K', 'Filipino/L', 'Filipino/M', 'Filipino/N', 'Filipino/O', 'Filipino/P', 'Filipino/Q', 'Filipino/R', 'Filipino/S', 'Filipino/T', 'Filipino/U', 'Filipino/V', 'Filipino/W', 'Filipino/X', 'Filipino/Y', 'Filipino/Z', 'India/A', 'India/B', 'India/C', 'India/D', 'India/E', 'India/F', 'India/G', 'India/H', 'India/I', 'India/J', 'India/K', 'India/L', 'India/M', 'India/N', 'India/O', 'India/P', 'India/Q', 'India/R', 'India/S', 'India/T', 'India/U', 'India/V', 'India/W', 'India/X', 'India/Y', 'India/Z', 'Indonesia/A', 'Indonesia/B', 'Indonesia/C', 'Indonesia/D', 'Indonesia/E', 'Indonesia/F', 'Indonesia/G', 'Indonesia/H', 'Indonesia/I', 'Indonesia/J', 'Indonesia/K', 'Indonesia/L', 'Indonesia/M', 'Indonesia/N', 'Indonesia/O', 'Indonesia/P', 'Indonesia/Q', 'Indonesia/R', 'Indonesia/S', 'Indonesia/T', 'Indonesia/U', 'Indonesia/V', 'Indonesia/W', 'Indonesia/X', 'Indonesia/Y', 'Indonesia/Z', 'Malaysia/A', 'Malaysia/B', 'Malaysia/C', 'Malaysia/D', 'Malaysia/E', 'Malaysia/F', 'Malaysia/G', 'Malaysia/H', 'Malaysia/I', 'Malaysia/J', 'Malaysia/K', 'Malaysia/L', 'Malaysia/M', 'Malaysia/N', 'Malaysia/O', 'Malaysia/P', 'Malaysia/Q', 'Malaysia/R', 'Malaysia/S', 'Malaysia/T', 'Malaysia/U', 'Malaysia/V', 'Malaysia/W', 'Malaysia/X', 'Malaysia/Y', 'Malaysia/Z']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be875d6-d776-422d-b3f0-fc5ed0e5666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the class labels after training\n",
    "with open(\"class_indices.json\", \"w\") as f:\n",
    "    json.dump(train_data.class_indices, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3d4ab8-2800-423a-ac9d-6a7f041f3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f32aa06a-c07f-483b-bc65-5cc1326e7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "# x = Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
    "# x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e0eec3-0e2d-47be-bb67-e95201921e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = Dense(num_classes, activation='softmax', name=\"classification_output\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64561968-90c8-46f8-95bd-9579bb608d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4493cc5e-2379-4b46-b1ff-76501ab5b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "277864ac-2ecc-4cec-85b1-91228638fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60640f4a-e8db-4724-b340-9166c6530e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2383s\u001b[0m 2s/step - accuracy: 0.9803 - loss: 0.0827 - val_accuracy: 0.7524 - val_loss: 1.6611 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2657s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0194 - val_accuracy: 0.9179 - val_loss: 0.5419 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2403s\u001b[0m 2s/step - accuracy: 0.9943 - loss: 0.0230 - val_accuracy: 0.6415 - val_loss: 57.9779 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2252s\u001b[0m 2s/step - accuracy: 0.9949 - loss: 0.0238 - val_accuracy: 0.9588 - val_loss: 0.7109 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2252s\u001b[0m 2s/step - accuracy: 0.9878 - loss: 0.0562 - val_accuracy: 0.9501 - val_loss: 0.4735 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2306s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.0144 - val_accuracy: 0.9911 - val_loss: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2448s\u001b[0m 2s/step - accuracy: 0.9947 - loss: 0.0247 - val_accuracy: 0.9919 - val_loss: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2282s\u001b[0m 2s/step - accuracy: 0.9909 - loss: 0.0768 - val_accuracy: 0.9090 - val_loss: 19.6966 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2243s\u001b[0m 1s/step - accuracy: 0.9969 - loss: 0.0137 - val_accuracy: 0.9745 - val_loss: 0.1188 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m1498/1498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2289s\u001b[0m 2s/step - accuracy: 0.9956 - loss: 0.0183 - val_accuracy: 0.9745 - val_loss: 0.0968 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x185924ea790>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=10, steps_per_epoch=len(train_data), validation_data=val_data, validation_steps=len(val_data),callbacks=[early_stopping, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abffc933-e109-4f5d-ba4f-3a51089424e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"sign_language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16401f18-81d7-4bad-955d-51db477faa94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
